{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMH9eIdqpZBZZYzP9djrGCD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n6L5Ezj0MaSb","executionInfo":{"status":"ok","timestamp":1732121093683,"user_tz":-330,"elapsed":474,"user":{"displayName":"Ashutosh Dalvi","userId":"07470330870447325647"}},"outputId":"dc07edda-351b-49a5-b515-b4486633299b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Text:\n","chains are useful for generating sequences of text where each word depends on the previous ones.\n"]}],"source":["import random\n","from collections import defaultdict\n","\n","def train_markov_chain(text, order=1):\n","    \"\"\"\n","    Trains a Markov Chain based on the given text.\n","\n","    Parameters:\n","        text (str): Input text to train the model.\n","        order (int): The order of the Markov chain.\n","\n","    Returns:\n","        defaultdict: A dictionary mapping states to possible next states.\n","    \"\"\"\n","    # Tokenize the text into words\n","    words = text.split()\n","\n","    # Create a dictionary to store transitions\n","    transition_dict = defaultdict(list)\n","\n","    # Populate the dictionary with transitions\n","    for i in range(len(words) - order):\n","        # Current state: a tuple of 'order' words\n","        current_state = tuple(words[i:i+order])\n","        # Next word\n","        next_word = words[i+order]\n","        # Add the transition\n","        transition_dict[current_state].append(next_word)\n","\n","    return transition_dict\n","\n","def generate_text(markov_chain, order=1, length=50):\n","    \"\"\"\n","    Generates text using a trained Markov Chain.\n","\n","    Parameters:\n","        markov_chain (defaultdict): The trained Markov Chain.\n","        order (int): The order of the Markov chain.\n","        length (int): The length of the generated text.\n","\n","    Returns:\n","        str: The generated text.\n","    \"\"\"\n","    # Start with a random state\n","    current_state = random.choice(list(markov_chain.keys()))\n","    generated_words = list(current_state)\n","\n","    for _ in range(length - order):\n","        # Get possible next words\n","        next_words = markov_chain.get(current_state, None)\n","        if not next_words:  # If no transitions available, stop generation\n","            break\n","        # Choose the next word randomly\n","        next_word = random.choice(next_words)\n","        generated_words.append(next_word)\n","        # Update the current state\n","        current_state = tuple(generated_words[-order:])\n","\n","    return ' '.join(generated_words)\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Example text\n","    sample_text = \"\"\"Markov chains are useful for generating sequences of text where\n","    each word depends on the previous ones.\"\"\"\n","\n","    # Train a Markov Chain model\n","    order = 2  # Adjust the order for more context\n","    markov_chain = train_markov_chain(sample_text, order)\n","\n","    # Generate text\n","    generated_text = generate_text(markov_chain, order, length=50)\n","    print(\"Generated Text:\")\n","    print(generated_text)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"3g2xkfzhMijq","executionInfo":{"status":"ok","timestamp":1732121089909,"user_tz":-330,"elapsed":528,"user":{"displayName":"Ashutosh Dalvi","userId":"07470330870447325647"}}},"execution_count":6,"outputs":[]}]}